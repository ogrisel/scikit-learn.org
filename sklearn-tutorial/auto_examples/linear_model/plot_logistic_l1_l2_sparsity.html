

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>L1 Penalty and Sparsity in Logistic Regression &mdash; scikit-learn 0.11-git documentation</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.11-git',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="top" title="scikit-learn 0.11-git documentation" href="../../index.html" />
    <link rel="up" title="Examples" href="../index.html" />
    <link rel="next" title="Path with L1- Logistic Regression" href="plot_logistic_path.html" />
    <link rel="prev" title="Lasso model selection: Cross-Validation / AIC / BIC" href="plot_lasso_model_selection.html" />
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>
    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="../../index.html">
            <img src="../../_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="../../install.html">Download</a></li>
            <li><a href="../../support.html">Support</a></li>
            <li><a href="../../user_guide.html">User Guide</a></li>
            <li><a href="../index.html">Examples</a></li>
            <li><a href="../../modules/classes.html">Reference</a></li>
       </ul>

<div class="search_form">

<div id="cse" style="width: 100%;"></div>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">
  google.load('search', '1', {language : 'en'});
  google.setOnLoadCallback(function() {
    var customSearchControl = new google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
    customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
    var options = new google.search.DrawOptions();
    options.setAutoComplete(true);
    customSearchControl.draw('cse', options);
  }, true);
</script>

</div>
          </div> <!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

    <div class="sphinxsidebar">
	<div class="rel">
	
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  -->
	<div class="rellink">
	<a href="plot_lasso_model_selection.html" title="Lasso model selection: Cross-Validation / AIC / BIC"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    Lasso model sele...
	    </span>
	    <span class="hiddenrellink">
	    Lasso model selection: Cross-Validation / AIC / BIC
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="plot_logistic_path.html" title="Path with L1- Logistic Regression"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    Path with L1- Lo...
	    </span>
	    <span class="hiddenrellink">
	    Path with L1- Logistic Regression
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page -->
	<div class="spacer">
	&nbsp;
	</div>
	<div class="rellink">
	<a href="../index.html" title="Examples" >
	Up
	<br>
	<span class="smallrellink">
	Examples
	</span>
	<span class="hiddenrellink">
	Examples
	</span>
	
	</a>
	</div>
    </div>
    <p style="text-align: center">This documentation is
    for scikit-learn <strong>version 0.11-git</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3>Citing</h3>
    <p>If you use the software, please consider
    <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">L1 Penalty and Sparsity in Logistic Regression</a></li>
</ul>

    
    </div>

      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="l1-penalty-and-sparsity-in-logistic-regression">
<span id="example-linear-model-plot-logistic-l1-l2-sparsity-py"></span><h1>L1 Penalty and Sparsity in Logistic Regression<a class="headerlink" href="#l1-penalty-and-sparsity-in-logistic-regression" title="Permalink to this headline">Â¶</a></h1>
<p>Comparison of the sparsity (percentage of zero coefficients) of solutions when
L1 and L2 penalty are used for different values of C. We can see that large
values of C give more freedom to the model.  Conversely, smaller values of C
constrain the model more. In the L1 penalty case, this leads to sparser
solutions.</p>
<p>We classify 8x8 images of digits into two classes: 0-4 against 5-9.
The visualization shows coefficients of the models for varying C.</p>
<img alt="../../_images/plot_logistic_l1_l2_sparsity_1.png" class="align-center" src="../../_images/plot_logistic_l1_l2_sparsity_1.png" />
<p><strong>Script output</strong>:</p>
<div class="highlight-python"><pre>C=10.000000
Sparsity with L1 penalty: 87.500000
score with L1 penalty: 0.797440
Sparsity with L2 penalty: 4.687500
score with L2 penalty: 0.885364
C=100.000000
Sparsity with L1 penalty: 53.125000
score with L1 penalty: 0.895938
Sparsity with L2 penalty: 4.687500
score with L2 penalty: 0.907067
C=1000.000000
Sparsity with L1 penalty: 12.500000
score with L1 penalty: 0.910406
Sparsity with L2 penalty: 4.687500
score with L2 penalty: 0.909850</pre>
</div>
<p><strong>Python source code:</strong> <a class="reference download internal" href="../../_downloads/plot_logistic_l1_l2_sparsity.py"><tt class="xref download docutils literal"><span class="pre">plot_logistic_l1_l2_sparsity.py</span></tt></a></p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">print</span> <span class="n">__doc__</span>

<span class="c"># Authors: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="c">#          Mathieu Blondel &lt;mathieu@mblondel.org&gt;</span>
<span class="c">#          Andreas Mueller &lt;amueller@ais.uni-bonn.de&gt;</span>
<span class="c"># License: BSD Style.</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="kn">as</span> <span class="nn">pl</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Scaler</span>

<span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">Scaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c"># classify small against large digits</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>


<span class="c"># Set regularization parameter</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">C</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="mf">10.</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)):</span>
    <span class="c"># turn down tolerance for short training time</span>
    <span class="n">clf_l1_LR</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">&#39;l1&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">clf_l2_LR</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">&#39;l2&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">clf_l1_LR</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">clf_l2_LR</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">coef_l1_LR</span> <span class="o">=</span> <span class="n">clf_l1_LR</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">coef_l2_LR</span> <span class="o">=</span> <span class="n">clf_l2_LR</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="c"># coef_l1_LR contains zeros due to the</span>
    <span class="c"># L1 sparsity inducing norm</span>

    <span class="n">sparsity_l1_LR</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">coef_l1_LR</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="n">sparsity_l2_LR</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">coef_l2_LR</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

    <span class="k">print</span> <span class="s">&quot;C=</span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">C</span>
    <span class="k">print</span> <span class="s">&quot;Sparsity with L1 penalty: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">sparsity_l1_LR</span>
    <span class="k">print</span> <span class="s">&quot;score with L1 penalty: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">clf_l1_LR</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">&quot;Sparsity with L2 penalty: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">sparsity_l2_LR</span>
    <span class="k">print</span> <span class="s">&quot;score with L2 penalty: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">clf_l2_LR</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">l1_plot</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">l2_plot</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">l1_plot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;L1 penalty&quot;</span><span class="p">)</span>
        <span class="n">l2_plot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;L2 penalty&quot;</span><span class="p">)</span>

    <span class="n">l1_plot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coef_l1_LR</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;nearest&#39;</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s">&#39;binary&#39;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">l2_plot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coef_l2_LR</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;nearest&#39;</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s">&#39;binary&#39;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">pl</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="s">&quot;C = </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">C</span><span class="p">)</span>

    <span class="n">l1_plot</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">l1_plot</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
    <span class="n">l2_plot</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">l2_plot</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>

<span class="n">pl</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010â2011, scikit-learn developers (BSD License).
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.2. Design by <a href="http://webylimonada.com">Web y Limonada</a>.
    <span style="padding-left: 5ex;">
    <a href="../../_sources/auto_examples/linear_model/plot_logistic_l1_l2_sparsity.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
  </body>
</html>