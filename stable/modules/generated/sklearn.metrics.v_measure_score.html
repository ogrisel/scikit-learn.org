

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>9.8.3.5. sklearn.metrics.v_measure_score &mdash; scikit-learn 0.9 documentation</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.9',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="top" title="scikit-learn 0.9 documentation" href="../../index.html" />
    <link rel="up" title="9. Class reference" href="../classes.html" />
    <link rel="next" title="9.8.4.1. sklearn.metrics.pairwise.euclidean_distances" href="sklearn.metrics.pairwise.euclidean_distances.html" />
    <link rel="prev" title="9.8.3.4. sklearn.metrics.completeness_score" href="sklearn.metrics.completeness_score.html" />
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>
    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="../../index.html">
            <img src="../../_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="../../install.html">Download</a></li>
            <li><a href="../../support.html">Support</a></li>
            <li><a href="../../user_guide.html">User Guide</a></li>
            <li><a href="../../auto_examples/index.html">Examples</a></li>
            <li><a href="../../developers/index.html">Development</a></li>
       </ul>

<div class="search_form">

<div id="cse" style="width: 100%;"></div>
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">
  google.load('search', '1', {language : 'en'});
  google.setOnLoadCallback(function() {
    var customSearchControl = new google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
    customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
    var options = new google.search.DrawOptions();
    options.setAutoComplete(true);
    customSearchControl.draw('cse', options);
  }, true);
</script>

</div>

          </div> <!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

    <!-- <div id="blue_tile"></div> -->

        <div class="sphinxsidebar">
        <div class="rel">
          <a href="sklearn.metrics.completeness_score.html" title="9.8.3.4. sklearn.metrics.completeness_score"
             accesskey="P">previous</a> |
          <a href="sklearn.metrics.pairwise.euclidean_distances.html" title="9.8.4.1. sklearn.metrics.pairwise.euclidean_distances"
             accesskey="N">next</a> |
          <a href="../../np-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
        

        <h3>This page</h3>
         <ul>
<li><a class="reference internal" href="#">9.8.3.5. sklearn.metrics.v_measure_score</a></li>
</ul>


        

        <h3>Citing</h3>
        <p>Please consider
	<a href="about.html#citing-the-scikit-learn">citing the
	scikit-learn</a>.
        </div>

      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="sklearn-metrics-v-measure-score">
<h1>9.8.3.5. sklearn.metrics.v_measure_score<a class="headerlink" href="#sklearn-metrics-v-measure-score" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="sklearn.metrics.v_measure_score">
<tt class="descclassname">sklearn.metrics.</tt><tt class="descname">v_measure_score</tt><big>(</big><em>labels_true</em>, <em>labels_pred</em><big>)</big><a class="headerlink" href="#sklearn.metrics.v_measure_score" title="Permalink to this definition">¶</a></dt>
<dd><p>V-Measure cluster labeling given a ground truth</p>
<p>The V-Measure is the hormonic mean between homogeneity and completeness:</p>
<blockquote>
<div>v = 2 * (homogeneity * completeness) / (homogeneity + completeness)</div></blockquote>
<p>This metric is independent of the absolute values of the labels:
a permutation of the class or cluster label values won&#8217;t change the
score value in any way.</p>
<p>This metric is furthermore symmetric: switching <cite>label_true</cite> with
<cite>label_pred</cite> will return the same score value. This can be useful to
measure the agreement of two independent label assignments strategies
on the same dataset when the real ground truth is not known.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters :</th><td class="field-body"><p class="first"><strong>labels_true</strong> : int array, shape = [n_samples]</p>
<blockquote>
<div><p>ground truth class labels to be used as a reference</p>
</div></blockquote>
<p><strong>labels_pred</strong> : array, shape = [n_samples]</p>
<blockquote>
<div><p>cluster labels to evaluate</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns :</th><td class="field-body"><p class="first"><strong>completeness: float</strong> :</p>
<blockquote class="last">
<div><p>score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition-see-also admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><tt class="xref py py-obj docutils literal"><span class="pre">-</span></tt>, <tt class="xref py py-obj docutils literal"><span class="pre">-</span></tt></p>
</div>
<p class="rubric">References</p>
<p>V-Measure: A conditional entropy-based external cluster evaluation measure
Andrew Rosenberg and Julia Hirschberg, 2007
<a class="reference external" href="http://acl.ldc.upenn.edu/D/D07/D07-1043.pdf">http://acl.ldc.upenn.edu/D/D07/D07-1043.pdf</a></p>
<p class="rubric">Examples</p>
<p>Perfect labelings are both homogeneous and complete, hence have score 1.0:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics.cluster</span> <span class="kn">import</span> <span class="n">v_measure_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_measure_score</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_measure_score</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>Labelings that assign all classes members to the same clusters
are complete be not homogeneous, hence penalized:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">v_measure_score</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>     
<span class="go">0.8...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_measure_score</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>     
<span class="go">0.66...</span>
</pre></div>
</div>
<p>Labelings that have pure clusters with members coming from the same
classes are homogeneous but un-necessary splits harms completeness
and thus penalize V-measure as well:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">v_measure_score</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>     
<span class="go">0.8...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_measure_score</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>     
<span class="go">0.66...</span>
</pre></div>
</div>
<p>If classes members are completly splitted accross different clusters,
the assignment is totally in-complete, hence the v-measure is null:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">v_measure_score</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>Clusters that include samples from totally different classes totally
destroy the homogeneity of the labeling, hence:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">v_measure_score</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">0.0</span>
</pre></div>
</div>
</dd></dl>

</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        <p style="text-align: center">This documentation is relative
        to scikit-learn version 0.9<p>
        &copy; 2010–2011, scikit-learn developers (BSD License).
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.2. Design by <a href="http://webylimonada.com">Web y Limonada</a>.
    <span style="padding-left: 5ex;">
    <a href="../../_sources/modules/generated/sklearn.metrics.v_measure_score.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
  </body>
</html>